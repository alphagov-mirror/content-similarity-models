{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the use of cosine similarity measures on the money branch to improve its structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for identifying areas of the taxonomy where content is not well sorted and may require further curation. We're focusing on the money branch.\n",
    "\n",
    "We're looking to explore and flag:\n",
    "\n",
    "1. Content in the wrong place (its semantically different to other items in that taxon)\n",
    "1. Odd taxon structure (content diversity, taxon size and depth)\n",
    "1. Taxons that need splitting (clusters of closely-related content exist within a taxon)\n",
    "1. Taxons that need merging (there's a large overlap in content tagging between branches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming for now that your working directory is at `/content-similarity-models/google-universal-encoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import pairwise_distances, pairwise_distances_chunked\n",
    "\n",
    "import altair as alt\n",
    "from altair import datum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedded sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_sentences = np.load('../data/embedded_sentences2019-02-11.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelled data\n",
    "We may also need to read the `labelled.csv` data to create some objects that will be used later. The labelled data is one of the inputs to the `get_homogeneity_scores_taxon.py script` that produces `taxon_homogeneity_df.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled = pd.read_csv(\n",
    "    '../data/2019-02-11/labelled.csv.gz',\n",
    "    compression='gzip',\n",
    "    low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare objects for later visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_id_to_base_path = dict(zip(labelled['taxon_id'], labelled['taxon_base_path']))\n",
    "\n",
    "#taxon_id_to_level = dict(zip(labelled['taxon_id'], labelled['level']))\n",
    "\n",
    "taxon_id_to_level1 = dict(zip(labelled['taxon_id'], labelled['level1taxon']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxons = labelled['taxon_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branch homogeneity\n",
    "Read the homogeneity data, which is a Pandas data frame output from the `get_homogeneity_scores_taxon.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_homogeneity_df = pd.read_csv(\"../data/taxon_homogeneity_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_homogeneity_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_homogeneity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore flagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Odd taxon structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcols = 6  # specify the number of columns you want\n",
    "level1taxons = taxon_homogeneity_df['level1taxon'].unique() \n",
    "\n",
    "\n",
    "money = taxon_homogeneity_df[taxon_homogeneity_df.level1taxon == 'Money'].copy()\n",
    "\n",
    "total_size = money['taxon_size'].sum().astype(str)\n",
    "\n",
    "money_plot = alt.Chart(money).mark_circle(size=60).encode(\n",
    "    alt.X(\n",
    "        'taxon_size:Q',\n",
    "        scale=alt.Scale(type='log', domain=(1, 10000)),\n",
    "        axis=alt.Axis(grid=False, title='log(topic_size)')\n",
    "    ),\n",
    "    alt.Y(\n",
    "        'mean_cosine_score:Q',\n",
    "        scale=alt.Scale(domain=(0, 0.6)),\n",
    "        axis=alt.Axis(grid=False, title='content diversity score')\n",
    "    ), \n",
    "    #color='taxon_level:N',\n",
    "    color=alt.Color('taxon_level:N', scale=alt.Scale(scheme='magma')),\n",
    "    opacity=alt.value(0.8), \n",
    "    tooltip=['taxon_base_path']\n",
    ").properties(\n",
    "        title='Money' + \", \" + total_size).interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_plot.save('money.html', scale_factor=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Content in the wrong place\n",
    "Content may have been tagged in the wrong place. How can we identify this? One idea is to look at the cosine similarity between each content item and all the others within a taxon and then inspect the ones with scores that are above a certain threshold (i.e. they're semantically different to everything else)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: 'business tax' taxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the taxon ID as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btax_id = '28262ae3-599c-4259-ae30-3c83a5ec02a1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the embedded sentences (a numpy array) where it matches the business tax taxon ID. Indices for `embedded sentences` and `labelled` are the same, so `labelled` can be used to help filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btax_embedded = embedded_sentences[labelled['taxon_id'] == btax_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cosine similarity for all content item pairs in the taxon, convert to a Pandas data frame and then get the mean distances for each content item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btax_dist = pairwise_distances(\n",
    "    btax_embedded, \n",
    "    metric = 'cosine', \n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btax_dist_df = pd.DataFrame(btax_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btax_dist_df['mean'] = btax_dist.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btax_dist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many content items (rows) have a larger mean distance than the overall mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btax_dist_df[btax_dist_df['mean'] > btax_dist.mean()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this information to filter the data frame of labelled content items (`labelled`), leaving us with a data frame of the problem content.\n",
    "\n",
    "We can start by filtering the `labelled` data so we have only the content items that are in the business tax taxon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btax_content = labelled[labelled['taxon_id'] == btax_id].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btax_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now return content items from the data frame where the mean cosine similarity score is above a threshold value. These are the problem content items. Simplify the output to three columns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btax_content[['base_path', 'title', 'description']][btax_dist_df['mean'] > 0.65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get odd content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_misplaced_content (\n",
    "    taxon_id = '28262ae3-599c-4259-ae30-3c83a5ec02a1',\n",
    "    similarity_threshold = 0.65,\n",
    "    embedded_sentences_data = embedded_sentences,\n",
    "    labelled_data = labelled\n",
    "):\n",
    "    \n",
    "    \"\"\"Identify content items that seem out of place in a given taxon.\n",
    "    The cosine-similarity score (CSS) for each content item is calculated.\n",
    "    Content items are extracted if their mean score is above a particular threshold (default 0.65).\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Taxon ID: ', taxon_id)\n",
    "    print('Similarity threshold:', similarity_threshold)\n",
    "    \n",
    "    # Get embeddedings for the specified taxon ID\n",
    "    taxon_embedded = embedded_sentences[labelled['taxon_id'] == taxon_id]\n",
    "    \n",
    "    # Get distances between all content item pairs\n",
    "    taxon_dist = pairwise_distances(\n",
    "        taxon_embedded, \n",
    "        metric = 'cosine', \n",
    "        n_jobs = -1\n",
    "    )\n",
    "    \n",
    "    # As dataframe\n",
    "    taxon_dist_df = pd.DataFrame(taxon_dist)\n",
    "    \n",
    "    # Calculate a mean\n",
    "    taxon_dist_df['mean'] = taxon_dist.mean(axis = 1)\n",
    "    \n",
    "    # Get the rows of the labelled data (content items) that match the taxon ID\n",
    "    taxon_content = labelled[labelled['taxon_id'] == taxon_id].reset_index()\n",
    "    \n",
    "    # Content items that are above the similarity threshold\n",
    "    misplaced = taxon_content[['content_id', 'base_path', 'title', 'description']][taxon_dist_df['mean'] > similarity_threshold]\n",
    "    \n",
    "    return misplaced;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_misplaced_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Taxon could be split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Taxon could be merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
