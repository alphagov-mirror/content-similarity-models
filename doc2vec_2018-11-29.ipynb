{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import csv\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import progressbar\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from gensim.test.utils import get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ellieking/Documents/govuk-taxonomy-supervised-learning/data/2018-11-29'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR = os.getenv(\"DATADIR\")\n",
    "DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train test files\n",
    "clean_content = pd.read_csv(os.path.join(DATADIR, \"clean_content.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(clean_content, random_state=1234, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_corpus(df, tokens_only=False): \n",
    "    for i, row in df.iterrows():\n",
    "        if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(row['combined_text'])\n",
    "        else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(row['combined_text']), [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(sys.maxsize)\n",
    "                     \n",
    "        \n",
    "def read_corpus(fname, tokens_only=False): \n",
    "    \n",
    "    with open(fname, \"r\", encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "\n",
    "        for i, line in enumerate(reader):\n",
    "            yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line[-1]), [tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(tag_corpus(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = list(tag_corpus(test, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length = 172347\n",
      "test length = 57449\n"
     ]
    }
   ],
   "source": [
    "print('train length = {}'.format(len(train_corpus)))\n",
    "print('test length = {}'.format(len(test_corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "## Instantiate a Doc2Vec Object\n",
    "Now, we'll instantiate a Doc2Vec model with a vector size with 300 words and iterating over the training corpus 20 times. We set the minimum word count to 10 in order to discard words with very few occurrences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=10, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46min 39s, sys: 43.2 s, total: 47min 22s\n",
      "Wall time: 17min 46s\n"
     ]
    }
   ],
   "source": [
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring a Vector\n",
    "One important thing to note is that you can now infer a vector for any piece of text without having to re-train the model by passing a list of words to the model.infer_vector function. This vector can then be compared with other vectors via cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.75118792e-01 -8.95500124e-01  1.46018595e-01 -2.33786106e-01\n",
      "  7.14360595e-01  5.96053481e-01 -1.11715816e-01  2.75579989e-01\n",
      "  1.75319612e-01  6.63906217e-01  6.98049366e-01  6.32752329e-02\n",
      "  1.33808032e-01  2.49586567e-01  3.76466811e-01 -2.74105996e-01\n",
      "  2.22492069e-02  5.25327563e-01 -4.62037295e-01 -7.74631619e-01\n",
      "  6.34893715e-01  1.02416885e+00 -1.29518449e+00 -5.53773046e-01\n",
      "  1.99304491e-01 -1.87681839e-01  1.60499811e-01  4.52858508e-01\n",
      "  7.72842541e-02  3.07472825e-01  3.06219697e-01 -4.93364990e-01\n",
      " -3.75496566e-01  1.33307531e-01 -1.87995821e-01 -7.74305165e-01\n",
      " -7.67212510e-01 -5.18019736e-01  7.95392275e-01 -1.22042978e+00\n",
      " -2.88125962e-01 -3.49138789e-02 -7.52498627e-01 -3.43506485e-01\n",
      "  1.54965445e-01 -1.81098625e-01  5.05983472e-01  7.13778511e-02\n",
      " -5.67320228e-01 -1.59207523e-01  9.67527807e-01 -1.22648969e-01\n",
      " -1.09175898e-01 -9.75642279e-02  1.53443396e-01 -9.45146680e-01\n",
      "  4.43371832e-01 -1.95925295e-01  4.54822332e-01 -1.74526796e-01\n",
      " -7.21875548e-01  3.56558174e-01 -6.55643046e-01  2.50267804e-01\n",
      "  1.04378366e+00 -8.02229792e-02  8.22453320e-01  1.18011713e-01\n",
      "  1.08679108e-01  8.49264741e-01  5.76422751e-01 -7.00296104e-01\n",
      "  5.29555559e-01 -4.14944649e-01 -6.70551121e-01  2.89034635e-01\n",
      " -7.04412997e-01  1.89393729e-01 -1.98065564e-01  5.92475474e-01\n",
      "  6.87787116e-01  3.87877047e-01 -5.42493522e-01  1.58256543e+00\n",
      " -1.91963524e-01 -1.26999497e-01 -1.91558793e-01  5.39306819e-01\n",
      "  1.61553457e-01  3.77919525e-01 -2.56034076e-01 -9.61449742e-01\n",
      "  8.13102499e-02  6.84061646e-02 -2.36869678e-01 -9.56941489e-03\n",
      " -7.60387719e-01 -3.37723762e-01 -6.11619949e-01  3.57325524e-01\n",
      "  6.87983871e-01  8.19200754e-01 -1.78603858e-01  6.12938464e-01\n",
      " -7.27330387e-01  2.10062206e-01 -7.17876017e-01  7.96649158e-01\n",
      " -3.96520466e-01 -1.23698509e+00  7.22357491e-03  4.81548041e-01\n",
      "  3.00526500e-01 -1.04280782e+00 -4.63773280e-01  2.44048372e-01\n",
      " -6.25314787e-02  2.85403192e-01  6.62216425e-01  8.76720488e-01\n",
      " -7.30592350e-04  4.88303721e-01 -1.15269005e-01 -3.47606272e-01\n",
      "  4.70860064e-01 -7.87963867e-01  4.18150634e-01 -6.94323659e-01\n",
      " -3.82540315e-01  7.94311047e-01  5.26998758e-01  2.56435812e-01\n",
      " -1.89991726e-03 -1.46743119e-01  6.26540601e-01  6.75237551e-02\n",
      "  4.64511514e-02 -2.76443869e-01 -6.74084350e-02  1.17470160e-01\n",
      "  6.68188155e-01 -3.48568469e-01  5.76312721e-01  2.86553890e-01\n",
      "  3.74667376e-01 -1.56234547e-01 -2.95447931e-02  3.49029183e-01\n",
      "  3.36198747e-01 -5.74030101e-01  3.44050765e-01 -3.89822572e-01\n",
      "  1.15330625e+00  1.94794357e-01 -8.54769468e-01 -1.15328515e+00\n",
      " -1.09007381e-01  5.89454234e-01  2.34018583e-02 -7.26321200e-03\n",
      " -5.91111243e-01  1.12524700e+00 -8.34602565e-02  2.05493048e-01\n",
      " -6.39322817e-01  8.69811058e-01  3.74406800e-02 -2.10552126e-01\n",
      "  6.58351600e-01  7.06642151e-01  6.40810490e-01  1.02414536e+00\n",
      " -3.67883056e-01  4.71615613e-01  2.02027589e-01 -1.08712816e+00\n",
      "  3.47686291e-01  2.52301902e-01 -2.41035730e-01 -7.39143789e-01\n",
      " -4.07771826e-01  6.33383334e-01 -8.16959858e-01  1.70855388e-01\n",
      "  5.45759089e-02 -2.69520313e-01  2.24529058e-01 -5.13585567e-01\n",
      "  2.83512715e-02  3.66533339e-01  3.78213823e-01 -2.71939307e-01\n",
      "  1.16165686e+00 -9.25424695e-01  1.66676894e-01  1.18011869e-01\n",
      " -6.80707455e-01 -3.45222235e-01  8.77900064e-01 -1.12970924e+00\n",
      "  7.30074525e-01 -6.94509804e-01  1.65576315e+00  6.70595421e-03\n",
      "  1.72484800e-01 -2.95908332e-01  2.66999573e-01 -1.44189641e-01\n",
      "  1.52543843e-01  1.75014064e-01 -9.47462380e-01 -9.95407045e-01\n",
      " -2.37691522e-01 -1.63727775e-01 -2.05688879e-01  3.00022185e-01\n",
      "  3.54522109e-01 -7.68044114e-01  4.39464986e-01  2.35686347e-01\n",
      "  2.49161854e-01 -8.31308782e-01 -8.50263059e-01 -5.63106298e-01\n",
      " -3.92121553e-01  2.45591331e+00 -2.56354719e-01 -8.43604147e-01\n",
      " -1.95318218e-02  6.30980581e-02 -4.72311556e-01  5.53539455e-01\n",
      " -1.19156152e-01 -7.28192329e-01  3.24707359e-01 -9.27771851e-02\n",
      "  4.95233268e-01 -2.12740257e-01  1.19974160e+00 -1.04587281e+00\n",
      "  1.45320252e-01  4.76925552e-01 -1.15442149e-01  3.40458781e-01\n",
      " -7.23756179e-02  2.52452403e-01 -3.44440818e-01  1.92400828e-01\n",
      " -4.07558084e-01  1.07784405e-01 -6.27457976e-01 -7.77039453e-02\n",
      "  1.71735540e-01  4.87630367e-01 -6.79145634e-01  8.40356410e-01\n",
      "  5.57896830e-02 -1.32700741e-01 -1.52043492e-01 -4.40131307e-01\n",
      "  9.02729213e-01  6.58951879e-01  2.12580457e-01  9.78369176e-01\n",
      " -3.79895493e-02 -1.47727275e+00 -4.78575617e-01  3.42719257e-01\n",
      " -1.66732359e+00 -2.28690758e-01  1.56239763e-01 -2.70925879e-01\n",
      "  3.99575591e-01  4.60896641e-01 -6.37377262e-01  1.10689383e-02\n",
      " -6.98480010e-01  2.47202590e-01  5.72225690e-01 -3.36145461e-01\n",
      "  1.04938388e-01  2.61590779e-01  2.59509772e-01 -6.75525844e-01\n",
      " -4.47658211e-01  1.37583780e+00 -3.12518105e-02  3.67751569e-01\n",
      "  6.28210247e-01 -2.28058621e-01 -3.62308323e-01  1.72193944e-01\n",
      " -2.41767004e-01  1.26322255e-01  9.93985236e-01 -1.04386532e+00\n",
      " -3.65713656e-01 -5.27267098e-01 -4.16763246e-01  7.08887398e-01]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(model.infer_vector(train_corpus[0].words))\n",
    "print(train_corpus[0].tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that infer_vector() does not take a string, but rather a list of string tokens, which should have already been tokenized the same way as the words property of original training document objects.\n",
    "\n",
    "Also note that because the underlying training/inference algorithms are an iterative approximation problem that makes use of internal randomization, repeated inferences of the same text will return slightly different vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing Model\n",
    "To assess our new model, we'll first infer new vectors for each document of the training corpus and see how often the document found itself tobe the nearest document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(train_corpus, model):\n",
    "    train_auto_nearest = []\n",
    "    random.seed(1234)\n",
    "    sample_1000 = random.sample(train_corpus, 1000)\n",
    "\n",
    "    for doc_id in tqdm_notebook(range(len(sample_1000))):\n",
    "        inferred_vector = model.infer_vector(sample_1000[doc_id].words)\n",
    "        sims = model.docvecs.most_similar([inferred_vector], topn=2)\n",
    "        found_itself_nearest = int(np.where(sims[0][0]==sample_1000[doc_id].tags[0], 1, 0))\n",
    "        train_auto_nearest.append(found_itself_nearest)\n",
    "    \n",
    "    \n",
    "    x = collections.Counter(train_auto_nearest)\n",
    "    train_percent_auto_similar = x[1]/(x[0]+x[1])*100\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"The percentage of 1000 training samples which found itself nearest = {}\".format(train_percent_auto_similar\n",
    "                                                                                          )\n",
    "         )\n",
    "    return train_percent_auto_similar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d3501f1fa6407bb184930698fec368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of 1000 training samples which found itself nearest = 90.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(train_corpus, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, 90% of the inferred documents are found to be most similar to itself and 10% it is mistakenly most similar to another document. the checking of an inferred-vector against a training-vector is a sort of 'sanity check' as to whether the model is behaving in a usefully consistent manner, though not a real 'accuracy' value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model\n",
    "Using the same approach above, we'll infer the vector for a randomly chosen test document, and compare the document to our model by eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (36853): «re register your public limited company as private company rr this form is for public companies to re register as private limited company to re register from public company to private limited company you must have copy of the special resolution that the company should re register as private limited company unless previously delivered printed copy of the articles as proposed to be amended completed form rr forms need to be printed at full size on white sized paper rr application by public company for re registration as private limited company pdf kb pages»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d300,n5,w5,mc10,s0.001,t3):\n",
      "\n",
      "MOST (111323, 0.7750102281570435): «re register public company as private unlimited company rr use this form as an application by public company for re registration as private unlimited company you can use this form as an application by public company for re registration as private unlimited company if you have prescribed form of assent authenticated by or on behalf of all the members of the company printed copy of the company articles as proposed to be amended fee of is payable to companies house in respect of an application to re register make cheques and postal orders payable to companies house forms need to be printed at full size on white sized paper rr application by public company for re registration as private unlimited company pdf kb pages rr signature section continuation page pdf kb page»\n",
      "\n",
      "SECOND (114, 0.759843111038208): «re register an unlimited company as limited company rr use this form as an application by an unlimited company for re registration as private limited company this form can be used to apply to re register from an unlimited company to private limited company use this form if you have copy of the special resolution that the company should re register as private limited company unless previously delivered printed copy of the articles as proposed to be amended fee of is payable to companies house in respect of an application to re register make cheques and postal orders payable to companies house forms need to be printed at full size on white size paper application by an unlimited company for re registration as private limited company pdf kb pages»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND', 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (1377): «mr moore andrew richardson andrew richardson transport employment tribunal decision of judge burton on april read the full decision in mr moore andrew richardson andrew richardson transport»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d300,n5,w5,mc10,s0.001,t3):\n",
      "\n",
      "MOST (137170, 0.8068290948867798): «mr malinowski higgins transport ltd employment tribunal decision read the full decision in mr malinowski higgins transport ltd full»\n",
      "\n",
      "SECOND (47132, 0.7725715637207031): «aa london borough of haringey ukut aac upper tribunal administrative appeals chamber decision by judge levenson on june read the full decision in hs judicial summary transport»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=10)\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND', 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train on everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_corpus = list(tag_corpus(clean_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length = 229796\n"
     ]
    }
   ],
   "source": [
    "print('train length = {}'.format(len(entire_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_full = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=10, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_full.build_vocab(entire_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 2min 38s, sys: 59.8 s, total: 1h 3min 38s\n",
      "Wall time: 23min 57s\n"
     ]
    }
   ],
   "source": [
    "%time model_full.train(entire_corpus, total_examples=model_full.corpus_count, epochs=model_full.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44bce88f02ed47f89a9a73d9216caa59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of 1000 training samples which found itself nearest = 90.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90.2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(entire_corpus, model_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = get_tmpfile(os.path.join(\"/Volumes/GoogleDrive/Team Drives/GOV.UK teams/2018-2019/Q3/Knowledge up Q3/Data science/content_semantic_similarity/doc2vec_model\", \"doc2vec_model_2018-11-29.csv\"))\n",
    "model_full.save(fname)\n",
    "#model = Doc2Vec.load(fname)  # you can continue training with the loaded model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
